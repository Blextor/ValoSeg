


# -*- coding: utf-8 -*-
"""Labor4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NYbG2WFJewg4o2mtw9rVtQ02-df-qdnQ

# Bevezetés

A mai labor témája a szemantikus szegmentáció implementációja lesz.

## Installálás
"""

import subprocess
import sys

def install(package):
    subprocess.check_call([sys.executable, "-m", "pip", "install", package])


"""## Installáció ellenőrzése"""


#!nvcc --version
import torch
import nvidia_pyindex


#nvcc --version
#subprocess.call([sys.executable, "nvcc",  "--version"])
print(torch.cuda.is_available())

"""## Adatbázis letöltése"""
#subprocess.check_call([sys.executable, "wget", '"http://3dmr.iit.bme.hu/edu/DL/RoboCupSeg.zip"'])
#subprocess.check_call([sys.executable, "unzip -qq RoboCupSeg.zip"])
#subprocess.check_call([sys.executable, "rm RoboCupSeg.zip"])
#!wget "http://3dmr.iit.bme.hu/edu/DL/RoboCupSeg.zip"
#!unzip -qq RoboCupSeg.zip
#!rm RoboCupSeg.zip

"""# Megoldás

## DataLoader írása

### Segédfüggvények
"""

import torch
import re

def tryint(s):
  try:
    return int(s)
  except:
    return s

def alphanum_key(s):
  """ Turn a string into a list of string and number chunks.
      "z23a" -> ["z", 23, "a"]
  """
  return [ tryint(c) for c in re.split('([0-9]+)', s) ]

class ToLabel(object):
  def __call__(self, tensor):
      return torch.squeeze(tensor.long())

"""### Random horizontal flip"""

from PIL import Image
import random

class HorizontalFlip(object):
  def __call__(self, img):
    if random.random() < 0.5:
        return img.transpose(Image.FLIP_LEFT_RIGHT)
    return img

"""### Loader"""

import torch
import os.path as osp
from torch.utils import data
import glob
import numpy as np

class SSDataSet(data.Dataset):
  def __init__(self, root, split="train", img_transform=None, label_transform=None):
    self.root = root
    self.split = split
    self.images = []
    self.labels = []
    self.labels = []
    self.img_transform = img_transform
    self.label_transform = label_transform

    data_dir = osp.join(root, split)
    self.img_dir = osp.join(data_dir,"images")
    self.lab_dir = osp.join(data_dir,"labels")

    imgFiles = sorted(glob.glob1(self.img_dir, "*.jpg"),key=alphanum_key)
    labFiles = sorted(glob.glob1(self.lab_dir, "*.png"),key=alphanum_key)
    
    for img,lab in zip(imgFiles,labFiles):
      self.images.append(img)
      self.labels.append(lab)


  def __len__(self):
    return len(self.images)

  def __getitem__(self, index):
    img_file = osp.join( self.img_dir, self.images[index])
    lab_file = osp.join( self.lab_dir, self.labels[index])

    img = Image.open(img_file).convert('RGB')
    label = Image.open(lab_file).convert("I")

    seed = np.random.randint(2147483647)  # make a seed with numpy generator
    random.seed(seed)  # apply this seed to img tranfsorms
    if self.img_transform is not None:
      imgs = self.img_transform(img)
    else:
      imgs = img

    random.seed(seed)  # apply this seed to target tranfsorms
    if self.label_transform is not None:
      labels = self.label_transform(label)
    else:
      labels = label

    return imgs, labels

"""## Modell definiálása

### Conv réteg
"""

import torch
import torch.nn as nn

class Conv(nn.Module):
  def __init__(self, inplanes, planes, size=3, stride=1):
    super(Conv, self).__init__()
    self.conv = nn.Conv2d(inplanes, planes, kernel_size=size, padding=size // 2, stride=stride)
    self.bn = nn.BatchNorm2d(planes)

  def forward(self, x):
    return self.bn(torch.relu(self.conv(x)))

"""### Transpose Conv"""

class trConv(nn.Module):
  def __init__(self, inplanes, planes, size=3, stride=2):
    super(trConv, self).__init__()
    self.relu = nn.ReLU()
    self.conv = nn.ConvTranspose2d(inplanes, planes, kernel_size=size,
                          padding=size // 2, stride=stride, output_padding=1, bias=True)
    self.bn = nn.BatchNorm2d(planes)

  def forward(self, x):
    return self.bn(torch.relu(self.conv(x)))

"""### Modell"""

class FCN(nn.Module):
  def __init__(self, planes, numClass=5):
    super(FCN, self).__init__()
    self.c1 = Conv(3,planes)
    self.d1 = Conv(planes,planes*2,stride=2)
    self.c2 = Conv(planes*2,planes*2)
    self.d2 = Conv(planes*2,planes*4,stride=2)
    self.c3 = Conv(planes*4,planes*4)
    self.d3 = Conv(planes*4,planes*8,stride=2)
    self.c4 = Conv(planes*8,planes*8)
    self.d4 = Conv(planes*8,planes*16,stride=2)
    self.c5 = Conv(planes*16,planes*16)
    
    self.u1 = trConv(planes*16,planes*8)
    self.u2 = trConv(planes*8,planes*4)
    self.u3 = trConv(planes*4,planes*2)
    self.u4 = trConv(planes*2,planes)
    
    self.classifier = nn.Conv2d(planes, numClass, 5, padding=2)
  
  def forward(self,x):
    l1 = self.c1(x)
    l2 = self.c2(self.d1(l1))
    l3 = self.c3(self.d2(l2))
    l4 = self.c4(self.d3(l3))
    l5 = self.c5(self.d4(l4))
    u4 = self.u1(l5) + l4
    u3 = self.u2(u4) + l3
    u2 = self.u3(u3) + l2
    u1 = self.u4(u2) + l1
    
    return self.classifier(u1)

"""## Train függvény"""

from IPython.display import HTML, display

def progress(value, max=100):
    return HTML("""
        <progress
            value='{value}'
            max='{max}',
            style='width: 100%'
        >
            {value}
        </progress>
    """.format(value=value, max=max))

def train(epoch):

  # variables for loss
  running_loss = 0.0
  correct = 0.0
  total = 0

  # set the network to train (for batchnorm and dropout)
  net.train()

  # Create progress bar
  #bar = display(progress(0, len(trainLoader)), display_id=True)

  # Epoch loop
  for i, data in enumerate(trainLoader, 0):
    # get the inputs
    inputs, labels = data

    # Convert to cuda conditionally
    inputs, labels = inputs.cuda(), labels.cuda()


    # zero the parameter gradients
    optimizer.zero_grad()

    # forward + backward + optimize
    outputs = net(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

    # compute statistics
    running_loss += loss.item()
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += torch.sum( predicted.data == labels.data ).item()/(160*128)*100

    # Update progress bar
    #bar.update(progress(i+1, len(trainLoader)))

  # print and plot statistics
  tr_loss = running_loss / len(trainLoader)
  tr_corr = correct / total

  print("Epoch [%d] Training Loss: %.4f Training Pixel Acc: %.2f" % (epoch+1, tr_loss, tr_corr))

  return tr_loss,tr_corr

"""## Val függvény"""

def val(epoch):

  # variables for loss
  running_loss = 0.0
  correct = 0.0
  total = 0
  
  # IoU computation
  conf = torch.zeros(numClass,numClass)
  IoU = torch.zeros(numClass)
  labCnts = torch.zeros(numClass)

  # set the network to eval (for batchnorm and dropout)
  net.eval()

  # Create progress bar
  #bar = display(progress(0, len(testLoader)), display_id=True)

  # Epoch loop
  for i, data in enumerate(testLoader, 0):
    # get the inputs
    inputs, labels = data

    # Convert to cuda conditionally
    inputs, labels = inputs.cuda(), labels.cuda()

    # forward
    outputs = net(inputs)
    loss = criterion(outputs, labels)

    # compute statistics
    running_loss += loss.item()
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += torch.sum( predicted.data == labels.data ).item()/(160*128)*100
    
    bSize = labels.size(0)
    labSize = labels.size()[1:3]
    
    # Compute IoU
    maskPred = torch.zeros(numClass,bSize,int(labSize[0]), int(labSize[1])).long()
    maskTarget = torch.zeros(numClass,bSize,int(labSize[0]), int(labSize[1])).long()
    for currClass in range(numClass):
      maskPred[currClass] = predicted == currClass
      maskTarget[currClass] = labels == currClass

    for imgInd in range(bSize):
      for labIdx in range(numClass):
        labCnts[labIdx] += torch.sum(maskTarget[labIdx,imgInd]).item()
        for predIdx in range(numClass):
          inter = torch.sum(maskPred[predIdx,imgInd] & maskTarget[labIdx,imgInd]).item()
          conf[(predIdx, labIdx)] += inter
          if labIdx == predIdx:
            union = torch.sum(maskPred[predIdx,imgInd] | maskTarget[labIdx,imgInd]).item()
            if union == 0:
              IoU[labIdx] += 1
            else:
              IoU[labIdx] += inter/union

    # Update progress bar
    #bar.update(progress(i+1, len(testLoader)))

  # print and plot statistics
  for labIdx in range(numClass):
    for predIdx in range(numClass):
      conf[(predIdx, labIdx)] /= (labCnts[labIdx] / 100.0)
  meanClassAcc = 0.0
  meanIoU = torch.sum(IoU/total).item() / numClass * 100
  currLoss = running_loss/(i+1)
  for j in range(numClass):
    meanClassAcc += conf[(j,j)]/numClass
  print("Epoch [%d] Validation Loss: %.4f Validation Pixel Acc: %.2f Mean Class Acc: %.2f IoU: %.2f" %
        (epoch+1, running_loss/(i+1), correct/(total), meanClassAcc, meanIoU))

  return currLoss, correct/(total)

"""## Tanítás

### Dataloaderek
"""

import torchvision
import torchvision.transforms as transforms
from PIL import Image

numClass = 256

input_transform = transforms.Compose([
    transforms.Resize((128,160), Image.BILINEAR),
    transforms.ToTensor(),
    transforms.Normalize((0.49139968, 0.48215827, 0.44653124),
                         (0.24703233, 0.24348505, 0.26158768))

])
target_transform = transforms.Compose([
    transforms.Resize((128,160), Image.NEAREST),
    transforms.ToTensor(),
    ToLabel(),
])

input_transform_tr = transforms.Compose([
    transforms.Resize((128,160),Image.BILINEAR),
    HorizontalFlip(),
    transforms.ColorJitter(brightness=0.5,contrast=0.5,saturation=0.4,hue=0.3),
    transforms.ToTensor(),
    transforms.Normalize((0.49139968, 0.48215827, 0.44653124),
                         (0.24703233, 0.24348505, 0.26158768))

])
target_transform_tr = transforms.Compose([
    transforms.Resize((128,160), Image.NEAREST),
    HorizontalFlip(),
    transforms.ToTensor(),
    ToLabel(),
])

folder = "RoboCupSeg"
folder2 = "Valo2"
folder3 = folder2

trainLoader = data.DataLoader(SSDataSet(folder3, split="train", img_transform=input_transform_tr,
                                             label_transform=target_transform_tr),
                                  batch_size=8, shuffle=True)

testLoader = data.DataLoader(SSDataSet(folder3, split="val", img_transform=input_transform,
                                             label_transform=target_transform),
                                  batch_size=8, shuffle=True)

"""### Háló, Loss, Optimizer és Scheduler"""

# Commented out IPython magic to ensure Python compatibility.
import torch.optim as optim
from torch.optim import lr_scheduler

# %matplotlib inline
import matplotlib
import matplotlib.pyplot as plt

# Makes multiple runs comparable
torch.manual_seed(42)
torch.cuda.manual_seed(42)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

net = FCN(64,numClass).cuda()

criterion = nn.CrossEntropyLoss().cuda()

optimizer = optim.Adam(net.parameters(), lr=1e-1, weight_decay=1e-4)

borders = 50

scheduler = lr_scheduler.StepLR(optimizer,borders)

# Epoch counter
numEpoch = 250

trLosses = []
trAccs = []
valLosses = []
valAccs = []

for epoch in range(numEpoch):

  # Call train and val
  tr_loss,tr_corr = train(epoch)
  val_loss,val_corr = val(epoch)

  # Step with the scheduler
  scheduler.step()
  
  trLosses.append(tr_loss)
  trAccs.append(tr_corr)
  valLosses.append(val_loss)
  valAccs.append(val_corr)

# Finished
print('Finished Training')
plt.plot(trLosses)
plt.plot(valLosses)
plt.show()
plt.plot(trAccs)
plt.plot(valAccs)
plt.show()

"""## Vizualizáció

### Színezés
"""

def Colorize(gray_image):
  cmap = torch.ByteTensor([
      #[0,0,0],[255,0,0],[0,255,0],[0,0,255],[255,255,255]
      [41, 35, 190, ], [132, 225, 108, ], [214, 174, 82, ], [144, 73, 241, ], [241, 187, 233, ], [235, 179, 166, ],
      [219, 60, 135, ], [12, 62, 153, ], [36, 94, 13, ], [28, 6, 183, ], [71, 222, 179, ], [18, 77, 200, ],
      [67, 187, 139, ], [166, 31, 3, ], [90, 125, 9, ], [56, 37, 31, ], [93, 212, 203, ], [252, 150, 245, ],
      [69, 59, 19, ], [13, 137, 10, ], [28, 219, 174, ], [50, 32, 154, ], [80, 238, 64, ], [120, 54, 253, ],
      [18, 73, 50, ], [246, 158, 125, ], [73, 220, 173, ], [79, 20, 242, ], [68, 64, 102, ], [208, 107, 196, ],
      [48, 183, 50, ], [59, 161, 34, ], [246, 34, 145, ], [157, 225, 139, ], [31, 218, 176, ], [202, 153, 2, ],
      [185, 114, 157, ], [73, 44, 128, ], [126, 197, 153, ], [213, 233, 128, ], [178, 234, 201, ], [204, 83, 191, ],
      [103, 214, 191, ], [20, 214, 126, ], [45, 220, 142, ], [102, 131, 239, ], [87, 73, 97, ], [255, 105, 143, ],
      [97, 205, 209, ], [30, 157, 156, ], [22, 114, 114, ], [230, 29, 240, ], [132, 79, 74, ], [119, 2, 215, ],
      [232, 57, 44, ], [83, 203, 201, ], [18, 30, 51, ], [116, 158, 12, ], [244, 213, 212, ], [159, 212, 164, ],
      [89, 126, 53, ], [207, 50, 34, ], [244, 204, 207, ], [211, 144, 45, ], [72, 211, 143, ], [117, 230, 217, ],
      [29, 42, 229, ], [192, 247, 43, ], [120, 129, 135, ], [68, 14, 95, ], [80, 0, 212, ], [97, 141, 190, ],
      [123, 5, 21, ], [7, 59, 51, ], [130, 31, 24, ], [112, 146, 218, ], [100, 84, 206, ], [177, 133, 62, ],
      [105, 21, 248, ], [70, 106, 4, ], [150, 115, 14, ], [217, 22, 47, ], [103, 104, 212, ], [247, 74, 74, ],
      [208, 87, 104, ], [118, 250, 22, ], [187, 17, 173, ], [174, 36, 136, ], [121, 254, 82, ], [219, 37, 67, ],
      [229, 60, 244, ], [69, 211, 216, ], [40, 206, 11, ], [245, 197, 96, ], [89, 61, 151, ], [39, 138, 89, ],
      [118, 45, 208, ], [194, 201, 205, ], [104, 212, 73, ], [106, 121, 37, ], [8, 97, 64, ], [20, 177, 59, ],
      [106, 165, 17, ], [40, 193, 140, ], [214, 169, 11, ], [135, 151, 140, ], [47, 241, 21, ], [29, 154, 149, ],
      [193, 155, 225, ], [192, 126, 233, ], [168, 154, 167, ], [134, 194, 181, ], [84, 191, 154, ], [231, 217, 35, ],
      [209, 85, 144, ], [56, 40, 209, ], [217, 108, 161, ], [102, 94, 78, ], [225, 48, 156, ], [254, 217, 113, ],
      [159, 226, 165, ], [226, 12, 155, ], [180, 71, 101, ], [56, 42, 70, ], [137, 169, 130, ], [121, 122, 118, ],
      [120, 194, 99, ], [177, 38, 223, ], [218, 41, 109, ], [62, 98, 224, ], [150, 18, 52, ], [191, 57, 166, ],
      [63, 137, 94, ], [241, 109, 14, ], [227, 108, 40, ], [161, 30, 32, ], [29, 203, 194, ], [3, 63, 65, ],
      [7, 132, 15, ], [20, 5, 101, ], [27, 40, 97, ], [201, 197, 231, ], [44, 142, 70, ], [54, 8, 220, ],
      [243, 168, 141, ], [254, 190, 242, ], [235, 113, 255, ], [160, 208, 59, ], [117, 6, 140, ], [126, 135, 120, ],
      [115, 77, 208, ], [190, 130, 190, ], [219, 194, 70, ], [65, 43, 140, ], [250, 48, 127, ], [112, 240, 167, ],
      [84, 134, 50, ], [149, 170, 91, ], [104, 19, 11, ], [230, 252, 245, ], [202, 190, 125, ], [159, 137, 138, ],
      [65, 27, 253, ], [184, 79, 104, ], [246, 114, 123, ], [20, 153, 205, ], [211, 13, 240, ], [68, 58, 180, ],
      [166, 102, 83, ], [51, 11, 203, ], [161, 16, 94, ], [76, 236, 3, ], [76, 115, 230, ], [5, 180, 49, ],
      [14, 170, 173, ], [207, 213, 176, ], [202, 39, 255, ], [216, 157, 20, ], [77, 244, 121, ], [39, 89, 66, ],
      [124, 156, 193, ], [248, 205, 140, ], [135, 32, 35, ], [100, 184, 166, ], [135, 149, 76, ], [176, 90, 141, ],
      [78, 45, 153, ], [231, 61, 177, ], [96, 222, 177, ], [128, 173, 8, ], [65, 233, 103, ], [65, 165, 213, ],
      [159, 228, 24, ], [159, 21, 66, ], [0, 38, 254, ], [76, 209, 33, ], [4, 147, 47, ], [179, 143, 115, ],
      [83, 64, 67, ], [138, 175, 126, ], [202, 111, 213, ], [207, 211, 161, ], [149, 206, 90, ], [190, 101, 39, ],
      [42, 246, 7, ], [173, 161, 190, ], [101, 166, 180, ], [201, 192, 105, ], [50, 52, 9, ], [44, 77, 1, ],
      [143, 23, 86, ], [198, 219, 157, ], [200, 166, 216, ], [11, 136, 129, ], [56, 97, 107, ], [104, 18, 98, ],
      [249, 84, 208, ], [231, 113, 23, ], [72, 120, 13, ], [146, 41, 29, ], [134, 41, 153, ], [114, 219, 116, ],
      [28, 250, 79, ], [55, 184, 181, ], [176, 149, 87, ], [245, 223, 128, ], [108, 109, 141, ], [116, 217, 139, ],
      [67, 101, 17, ], [8, 165, 246, ], [121, 189, 247, ], [235, 21, 184, ], [224, 225, 96, ], [143, 110, 60, ],
      [123, 244, 91, ], [98, 138, 138, ], [143, 39, 92, ], [247, 229, 135, ], [74, 59, 50, ], [155, 97, 64, ],
      [132, 198, 195, ], [177, 167, 48, ], [74, 16, 238, ], [117, 111, 3, ], [47, 158, 106, ], [239, 16, 80, ],
      [155, 200, 129, ], [67, 41, 40, ], [138, 246, 233, ], [158, 71, 161, ], [129, 72, 49, ], [108, 205, 164, ],
      [158, 222, 129, ], [163, 140, 152, ], [16, 255, 154, ], [67, 205, 207, ]
      ])
  size = gray_image.size()
  color_image = torch.ByteTensor(3, size[0], size[1]).fill_(0)

  for label in range(0, len(cmap)):
      mask = (label == gray_image).cpu()
      color_image[0][mask] = cmap[label][0]
      color_image[1][mask] = cmap[label][1]
      color_image[2][mask] = cmap[label][2]

  return color_image

"""### Egy minibatch"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib.pyplot import imshow
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image

for i, (images, labels) in enumerate(testLoader):
    images = images.cuda()
    pred = net(images)
    _, predClass = torch.max(pred, 1)
    bSize = images.size(0)
    for j in range(bSize):
        label = Image.fromarray(Colorize(predClass[j]).permute(1, 2, 0).numpy().astype('uint8'))
        img = Image.fromarray(((images[j].permute(1, 2, 0).cpu().numpy()/4 + 0.5)*240).astype('uint8'))
        plt.figure()
        plt.subplot(1, 2, 1)
        plt.axis('off')
        plt.grid(b=None)
        imshow(img)
        plt.subplot(1, 2, 2)
        plt.axis('off')
        plt.grid(b=None)
        imshow(label)
    plt.show()
    break
